<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Paper | SecDr]]></title>
  <link href="http://secdr.github.io/categories/paper/atom.xml" rel="self"/>
  <link href="http://secdr.github.io/"/>
  <updated>2015-10-17T22:25:42-07:00</updated>
  <id>http://secdr.github.io/</id>
  <author>
    <name><![CDATA[SecDr]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[牛人看外国文献的方法]]></title>
    <link href="http://secdr.github.io/2015/10/17/niu-ren-kan-wai-guo-wen-xian-de-fang-fa/"/>
    <updated>2015-10-17T22:20:06-07:00</updated>
    <id>http://secdr.github.io/2015/10/17/niu-ren-kan-wai-guo-wen-xian-de-fang-fa</id>
    <content type="html"><![CDATA[<p>牛人一
（从Ph.D到现在工作半年,发了12 篇paper, 7 篇first author.）我现在每天还保持读至少2-3 篇的文献的习惯.读文献有不同的读法.但最重要的自己总结概括这篇文献到底说了什么,否则就是白读,读的时候好像什么都明白,一合上就什么都不知道,这是读文献的大忌,既浪费时间,最重要的是,没有养成良好的习惯,导致以后不愿意读文献.</p>

<ol>
<li><p>每次读完文献 (不管是细读还是粗读), 合上文献后,想想看,文章最重要的 take home message 是什么, 如果不知道,就从abstract,conclusion 里找, 并且从discuss 里最好确认一下. 这样一来, 一篇文章就过关了. take home message 其实都不会很多, 基本上是一些concepts, 如果你发现你需要记得很多,那往往是没有读到重点.</p></li>
<li><p>扩充知识面的读法, 重点读introduction, 看人家提出的问题,以及目前的进展 类似的文章, 每天读一两篇,一个月内就基本上对这个领域的某个方向有个大概的了解.读好的review 也行, 但这样人容易懒惰.</p></li>
<li><p>为了写文章的读法, 读文章的时候, 尤其是看discussion 的时候,看到好的英文句型, 最好有意识的记一下,看一下作者是谁,哪篇文章,哪个期刊, 这样以后照猫画虎写的时候,效率高些.比自己在那里半天琢磨出一个句子强的多. 当然,读的多,写的多,你需要记得句型就越少.其实很简单,有意识的去总结和记亿, 就不容易忘记.</p></li>
</ol>


<!--more-->


<p>科研牛人二告诉研究生怎么看文献，怎么写论文</p>

<p>一、先看综述</p>

<p>先读综述,可以更好地认识课题,知道已经做出什么，自己要做什么,,还有什么问题没有解决。对于国内文献一般批评的声音很多.但它是你迅速了解你的研究领域的入口,在此之后,你再看外文文献会比一开始直接看外文文献理解的快得多。而国外的综述多为本学科的资深人士撰写，涉及范围广，可以让人事半功倍。</p>

<p>二、有针对地选择文献</p>

<p>针对你自己的方向,找相近的论文来读,从中理解文章中回答什么问题,通过哪些技术手段来证明,有哪些结论?从这些文章中,了解研究思路,逻辑推论,学习技术方法.</p>

<ol>
<li><p>关键词、主题词检索：</p>

<p> 关键词、主题词一定要选好，这样，才能保证你所要的内容的全面。因为，换个主题词，可以有新的内容出现。</p></li>
<li><p>检索某个学者：</p>

<p> 查SCI,知道了某个在这个领域有建树的学者，找他近期发表的文章。</p></li>
<li><p>参考综述检索：</p>

<p> 如果有与自己课题相关或有切入点的综述，可以根据相应的参考文献找到那些原始的研究论文。</p></li>
<li><p>注意文章的参考价值：</p>

<p> 刊物的影响因子、文章的被引次数能反映文章的参考价值。但要注意引用这篇文章的其它文章是如何评价这篇文章的</p></li>
</ol>


<p>三、如何阅读文献</p>

<ol>
<li><p>注重摘要：摘要可以说是一个论文的窗口。多数文章看摘要，少数文章看全文。真正有用的全文并不多，过分追求全文是浪费，不可走极端。当然只看摘要也是不对的。多数文章题目、摘要简单浏览后，直接把几个Figure 及Title 与legend 一看，一般能掌握大部分。</p></li>
<li><p>通读全文：读第一遍的时候一定要认真，争取明白每句的大意，能不查字典最好先不查字典。因为读论文的目的并不是学英语，而是获取信息，查了字典以后思维会非常混乱，往往读完全文不知所谓。可以在读的过程中将生字标记，待通读全文后再查找其意思。</p></li>
<li><p>归纳总结：较长的文章，容易遗忘。好在虽然论文的句子都长，但每段的句数并不多，可以每一段用一个词组标一个标题。</p></li>
<li><p>确立句子的架构，抓住主题：读 英文原版文献有窍门的。我们每个单词都认识读完了却不知他在说什么，这是最大的问题。在阅读的时候一定要看到大量的关系连词，他们承上启下引领了全文。中 国人喜欢罗列事实，给出一个观点然后就是大量的事实，这也是中文文献的特点，我们从小都在读这样的文章，很适应。西方人的文献注重逻辑和推理，从头到尾是 非常严格的，就像GRE 里面的阅读是一样的，进行的是大量重复、新旧观点的支持和反驳，有严格的提纲，尤其是好的杂志体现得越突出。读每一段落都要找到他 的主题，往往是很容易的，大量的无用信息可以一带而过，节约你大量的宝贵时间和精力。</p></li>
<li><p>增加阅读量：
由于刚刚接触这一领域，对许多问题还没有什么概念，读起来十分吃力，许多内容也读不懂。后来随着阅读量的增加，最后可以融汇贯通。所以，对新手而言，应当重视阅读文献的数量，积累多了，自然就由量变发展为质变了。</p></li>
</ol>


<p>四．提高阅读的效率</p>

<ol>
<li><p>集中时间看文献：</p>

<p> 看文献的时间越分散，浪费时间越多。集中时间看更容易联系起来，形成整体印象。</p></li>
<li><p>做好记录和标记：</p>

<p> 复印或打印的文献，直接用笔标记或批注。pdf 或html 格式的文献，可以用编辑器标亮或改变文字颜色。这是避免时间浪费的又一重要手段。否则等于没看。</p></li>
<li><p>阅读顺序：</p>

<p> 根据阅读目的选择合适的顺序。一般先看abstract、introduction，然后看discussion，最后看result 和method（结合图表）。</p></li>
</ol>


<p>五、文献的整理</p>

<ol>
<li>下载电子版文献时（caj，pdf，html），把文章题目粘贴为文件名（文件名不能有特殊符号）</li>
<li>不同主题存入不同文件夹。文件夹的题目要简短，如：PD，LTP,PKC，NO。</li>
<li>看过的文献归入子文件夹，最起码要把有用的和没用的分开。</li>
<li>重要文献根据重要程度在文件名前加001,002，003 编号，然后按名称排列图标，最重要的文献就排在最前了。而且重要文献要注意追踪。运气好，你可以得到更多的线索；运气不好，发现别人抢先了。据此修正你的实验。</li>
</ol>


<p>六、英文文章写作 （阅读文献的副产品）</p>

<ol>
<li>平时阅读文献，注意总结常用句型和常用短语（注意，文献作者必须是以英文为母语者，文献内容要与你的专业有关）。</li>
<li>找3-5 篇技术路线和统计方法与你的课题接近的文章，精读。?</li>
</ol>


<p>牛人三</p>

<p>本人英语基础不好，没过六级，所以在硕士的时候基本上看的外文文献很少，现在想想很后悔，2 年的时间少学了很多东西。上了博士，自己给自己的定位也高一些 了，开始打算硬着头皮咬着牙很不情愿的也要多看些外文文献，一开始看比较慢，有些很难理解，到现在大约仔细阅读了100 篇外文文献，泛读了100 篇外文文 章，受益匪浅，现在基本不怎么看中文的了，确实也觉得外文的质量就是高（也有凑数的烂文章），现在自己写外文的也很顺手了。谈几点自己的体会。我是材料专 业的。</p>

<ol>
<li><p>先找5 篇跟自己论文最相关的外文文章，花一个月的时间认认真真的看，反复看，要求全部读懂，不懂的地方可以和同学和老师交流一下。一个月以后你已经上路了。</p></li>
<li><p>如何读标题：不要忽视一篇论文的标题，看完标题以后想想要是让你写你怎么用一句话来表达这个标题，根据标题推测一下作者论文可能是什么内容。有时候一句比较长的标题让你写，你可能还不会表达。下次你写的时候就可以借鉴了</p></li>
<li><p>如何读摘要：快速浏览一遍，这里主要介绍这篇文章做了些什么。也许初看起来不好理解，看不懂，这时候不要气馁，不管它往下看，等你看完这篇文章的时候也许 你都明白了。因为摘要写的很简洁，省略了很多前提和条件，在你第一眼看到摘要而不明白作者意图的时候看不懂是正常的。</p></li>
<li><p>如何读引言（前言）：当你了解了你的研究领域的一些情况，看引言应该是一件很容易的事情了，都是介绍性的东西，写的应该都差不多，所以看文献多了以后看这部分的内容就很快了，一扫而过。有些老外写得很经典得句子要记下了，下次你写就可以用了。</p></li>
<li><p>如何读材料及试验：当你文献看多了以后，这部分内容也很简单了，无非就是介绍试验方法，自己怎么做试验的。很快就能把它看完了吧</p></li>
<li><p>如何看试验结果：看结果这部分一定要结合结果中的图和表看，这样看的快。主要看懂试验的结果，体会作者的表达方法（例如作者用不同的句子结构描述一些数字的结果）。有时看完以后再想想：就这么一点结果，别人居然可以大篇幅的写这么多，要是我可能半页就说完了？</p></li>
<li><p>如何看分析与讨论：这是一篇文章的重点，也是最花时间的。我一般把前面部分看完以后不急于看分析讨论。我会想要是我做出来这些结果我会怎么来写这部分分析 与讨论呢？然后慢慢看作者的分析与讨论，仔细体会作者观点，为我所用。当然有时候别人的观点比较新，分析比较深刻，偶尔看不懂也是情理之中。当你看的多 了，你肯定会看的越来越懂，自己的idea 越来越多</p></li>
<li><p>如何看结论：这个时候看结论就一目了然了，作后再反过去看看摘要，其实差不多</p></li>
<li><p>把下载的论文打印出来，根据与自己课题的相关性分三类，一类要精读，二类要泛读，三类要选择性的读。分别装订在一起</p></li>
<li><p>看完的文献千万不要丢在一边不管，3－4 个月一定要温习一遍，可以根据需要，对比自己的试验结果来看</p></li>
<li><p>学会记笔记，重要的结论，经典的句子，精巧的试验方案一定要记下来，供参考和学习</p></li>
<li><p>有些试验方法相同，结论不同的文献，可以批判性的阅读。我想要是你自己做试验多的话，你应该有这个能力判断谁的更对一点。出现试验方法相同，结论不同的原因有下：试验方法描述不详细，可能方法有差别；试验条件不一样；某些作者夸大结果，瞎编数据</p></li>
<li><p>有时间还是多看点文献吧，最好定个目标：在学术上超过自己的老板。因为老板一般不看文献，他们都是凭经验做事，很多新东西他们都不知道，慢慢的你老板会觉得你很厉害。反正我觉得多读了，读起来就快了，而且也会慢慢喜欢上看外文文献，收获自然也就多了。</p></li>
</ol>


<p>算起来从05 年读研开始到现在也快三年的时间了。在这段时间里，实验做得不是很多，文献倒是读了不少。原因呢，可能是老板也发现了我这个人属于那种眼高手低的人，干脆就让我做个文献阅读器了。从研一到现在每当老板脑子里出来一个想法，出来几个关键词，好了，下一步的工作就是交给我查阅和整理文献了。大家有空可以看看我发在论坛里的几个ppt，关于光催化、无铅压电陶瓷，微波介质陶瓷，纳米ZnO，此外关于Raman 光谱、多铁性材料。。。算起来前前后后看过——当然只能说看过，因为大部分都只是走马观花，没有精读——的文献应该不下三四百篇了。我估计每个方向单拿出来写个中文综述都差不多够了，可惜中文要版面费，想来老板也不会给出说了这么多废话，进入正题吧。有人也许会问，你是怎么看文献的，特别是一个以前没有接触的陌生领域。我的方法是，先看中文综述，然后是中文博士论文，而后是英文综述，最后是英文期刊文献。这样做的好处是，通过中文综述，你可以首先了解这行的基本名词，基本参量和常用的制备、表征方法。</p>

<p>我觉得这点很重要，因为如果直接英文上手的话，一些基本名词如果简单的想当然的翻译，往往会将你引入误区或造成歧义。同时中文综述里要包含了大量的英文参考文献，这就为后续的查找文献打下一个基础。</p>

<p>中文博士论文，特别是最近几年的，其第一章前言或是绪论所包含的信息量往往大于一篇综述的。因为它会更加详细的介绍该领域的背景以及相关理论知识，同时里面往往会提到国内外在本领域做得比较好的几个科研小组的相关研究方向。通过阅读就可以更清楚理清一个脉络。</p>

<p>英文综述，特别是那种invited paper 或是发表在高if 期刊上的，往往都是本领域的牛人们写的。对此要精读，要分析其文章的构架，特别要关于作者对各个方向的优缺点的评价以及对缺点的改进和展望。通过精读一篇好的英文综述，所获得的不只是对本领域现在发展状况的了解，同时也可以学会很多地道的英文表达。最后就是针对自己的课题查找阅读相关英文文献了。现在各大学图书馆里面的数据库都比较全，即使没有也可以通过网络上多种手段获取文献了。所以说文献的获取不是问题，问题在于查什么样的文献和怎么具体阅读整理文献。根据我的体会，我觉得有以下四类英文文献是我们所需要的：</p>

<ol>
<li><p>本领域核心期刊的文献。不同的研究方向有不同的核心期刊，这里也不能一概唯if 论了。比如说陶瓷类的核心期刊美陶的IF 也不过1.5 几，但上面的文章特别是feature artical 还是值得仔细阅读的。当然，首先你要了解所研究的核心期刊有哪些，这个就要靠学长、老板或者网上战友的互相帮助了。</p></li>
<li><p>本领域牛人或者主要课题组的文献。每个领域都有几个所谓的领军人物，他们所从事的方向往往代表目前的发展主流。因此阅读这些组里的文献就可以把握目前的研究重点。这里有人可能要问，我怎么知道谁是牛人呢？这里我个人有两个小方法。第一是在ISI 检索本领域的关键词，不要太多，这样你会查到很多文献，而后利用ISI 的refine 功能，就可以看到哪位作者发表的论文数量比较多，原则上一般发表论文数量较多的人和课题组就是这行里比较主要的了。还有一个方法，就是首先要了解本领域有哪些比较规模大型的国际会议，而后登陆会议主办者的网站一般都能看到关于会议的invited speaker的名字，做为邀请报告的报告人一般来说都是在该行有头有脸的人物了，呵呵</p></li>
<li><p>高引用次数的文章。一般来说高引用次数（如果不是靠自引堆上去的话）文章都是比较经典的文章，要么思路比较好，要么材料性能比较好，同时其文笔应该也不赖的话。多读这样的文章，体会作者对文章结构的把握和图表分析的处理，相信可以从中领悟很多东西的。</p></li>
<li><p>最后就是当你有了一定背景知识，开始做实验并准备写论文的时候需要看的文献了。我个人的经验是，首先要明确一点，你所做的实验想解决什么问题？是对原有材料的改进还是创造一种新的材料或者是新的制备方法，还是采用新的表征手段或是计算方法。明确这一点后，就可以有的放矢查找你需要的文献了。而且往往当你找到一篇与你研究方向相近的文章后，通过ISI 的反查，你可以找到引用它的文献和它引用的文献，从而建立一个文献树，更多的获取信息量。</p></li>
</ol>


<p>此外，我想提到的一点就是关于文献的整理。很多时候大家下文献都是很盲目，抱着一种先下来再说的思想。往往下来的文献不少，但只是空占者磁盘空间。不经过整理归类的文献就不是自己的文献，那根据什么来分类呢？</p>

<p>我有一个比较简单实用的方法，适用于那些拥有大量未读文献的。就是只关心三点：文章的前言的最后一部分（一般这部分都是提出作者为什么要进行这项工作，依据和方法），文章中的图表（提出采用的表征方法以及性能变化）和结论（是否实现了既定目标以及是否需要改进）。当然，如果全部精读相信工作量也不小。我的看法是尽可能用50 个字左右来归纳文章，说白了就是文章的目的（如改进某个性能或提出某种方法）＋表征手段（如XRD，IR，TEM 等）＋主要结论（如产物的性能）。当你按照这个方法归纳整理几十篇文献后，自然会有一个大致的了解，而后再根据你的笔记将文献分类整理，当你在写论文需要解释引用时再回头精读，我觉得这样会提高效率不少。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IEEE S&P 2015会议论文预读]]></title>
    <link href="http://secdr.github.io/2015/05/05/ieeesp2015papers/"/>
    <updated>2015-05-05T12:28:40-07:00</updated>
    <id>http://secdr.github.io/2015/05/05/ieeesp2015papers</id>
    <content type="html"><![CDATA[<p>作者及原文：<a href="http://www.vonwei.com/post/IEEESP2015Papers1.html">微月信-IEEE S&amp;P 2015会议论文预读</a></p>

<p>IEEE S&amp;P是Rank A的国际信息安全顶级会议，又称Oakland会议，尽管今年（2015）的会议召开还在五月份，不过<a href="http://www.ieee-security.org/TC/SP2015/program.html">官网</a>已经给出了会议程序列表，将进行三天，每天4个Session，每个Session都会将相似方向的最新安全研究成果进行展示。关注顶会的论文和Session方向对安全研究人员是非常必要的。在程序列表中，出现了三篇国内相关的文章，一篇一作来自中科院的Le Guan（本科室友，在国内读博期间分别发了两篇顶会了，很不错的成果，恭喜，另一篇在NDSS 2014上）；另一篇一作来自浙江大学的Boyuan He,看了下他们<a href="http://list.zju.edu.cn/">实验室主页</a>，果然也是有真正学术大牛在引导；最后一篇非一作，来自上海交大。</p>

<p>下面分别列出各个Session的论文，对于感兴趣的部分会简单的介绍一下。由于Session太多，将分三个博文分别进行介绍。由于会议主要论文将分三天报告完，因此每篇博文将介绍一天的论文。这篇先介绍第一天的论文，四个Session，共20篇文章。</p>

<!--more-->


<h3>Session 1：Hardware-Aided Security</h3>

<p>这个Session主要讨论硬件辅助的安全，如使用处理器比较新的硬件事务内存HTM，SGX等技术。该Session共五篇论文，其中第一个作报告的就是Le Guan。</p>

<p>（1）Protecting Private Keys against Memory Disclosure Attacks using Hardware Transactional Memory</p>

<p>第一篇来自中科院的Le Guan。现在很多密码系统的实现都是将密钥明文加载到内存中进行密码运算，这样私钥容易遭受内存泄露攻击，这种攻击可以通过软件方式实现（如OpenSSL的心血漏洞），也可以通过硬件方式实现（如冷启动攻击）。这篇论文提出的解决方案可以保护RSA私钥免遭上面的两类攻击。使用的方法就是基于硬件事务内存（hardware transactional memory - HTM），该论文是最先想到用HTM来保护敏感数据，以防止内存泄露攻击。论文实现的系统称为Mimosa，含羞草，很有意思的名字，这里就不猜测了。</p>

<p>（2）CHERI：A Hybrid Capability-System Architecture for Scalable Software Compartmentalization</p>

<p>（3）VC3: Trustworthy Data Analytics in the Cloud using SGX</p>

<p>本文提出了第一个实用的框架：允许用户在云上运行分布式的MapReduce计算，同时保证代码和数据的机密性，以及计算结果的正确性和完整性。该框架VC3运行在没有修改的Hadoop上，不过将Hadoop、OS和Hypervisor都排除在TCB（可信计算基）之外，这样即便Hadoop、OS和Hypervisor这些大系统组件被攻破，也不会影响VC3的机密性和完整性。VC3使用SGX处理器进行内存区域隔离，并部署新的协议来保证分布式MapReduce计算的安全。</p>

<p>（4）Virtual Proofs of Reality and Their Physical Implementation</p>

<p>虚拟现实证明及其物理实现，之前没有接触过这个概念，不过看起来很有意思。讨论的问题是：如何通过数字通信通道来证明物理语句（或者物理陈述），证明在两个隔离的本地系统之间进行（一个为证明者prover，另一个为验证者verifier）。证明的物理语句例子如，“证明者系统的一个特定对象的温度是X摄氏度”，“证明者系统的两个特定对象的距离为X”，“证明者系统的一个特定对象已经被不可逆的改变或者毁坏”。通过对这些例子的分析，本文的处理方法超越了经典安全传感器的范围。本文另一个独特的方面是其底层安全模型：既不假设证明者系统的安全密钥，也不假设其系统传感器硬件的防篡改和可信性（verifier不一定信任这些传感器硬件）。本文将这类新安全协议称为“虚拟现实证明”，或者“虚拟证明”，记为VP协议。为了分析提出的新概念，本文基于温度敏感的集成电路、无序光散射媒体以及量子系统来给出VPs例子。相应的协议向verifier证明prover系统特定物理对象的温度、相对位置，或者毁坏/修改。这些物理对象通常由verifier准备，并在VP协议之前交给prover。本文工作触及（部分进行了扩展）密码和安全领域的几个概念，包含物理不可克隆函数（PUF，physical unclonable functions），量子密码学（quantum cryptography），交互证明系统（interactive proof systems），以及最近的物理零知识证明（physical zero-knowledge proofs）。</p>

<p>（5）Using Hardware Features for Increased Debugging Transparency</p>

<h3>Session 2: Cryptocurrencies and Cybercrime</h3>

<p>第二个session主要关注密码货币和网络犯罪方面。这个session也是跟踪最近一段时间比较热门的比特币，安全研究者主要分析其系统属性。也有五篇论文，如下</p>

<p>（1）Every Second Counts: Quantifying the Negative Externalities of Cybercrime via Typosquatting</p>

<p>每天都有很多人称为网络犯罪的受害者，通常我们对受害系统的数量或者攻击者的利润都有比较好的了解，但是对人们承担的危害却了解不够。实际上，减少这种危害才是很多安全干预的最终目标。这些危害是如何犯下的，哪些犯罪造成这种危害，哪类攻击需要导致承受多少危害，为了有效减小危害的发生，这些都是需要了解的问题。本文提出了一种策略，可以对网络犯罪导致的危害进行量化，开发的新技术称为“意图推断（intent inference）”。意图推断可以达到三个目标：定义一个新的度量标准对用户遭受的危害进行量化；开发一个新的方法用来确定伪造域名；量化由各种伪造域名攻击者造成的危害。</p>

<p>（2）SoK: Bitcoin and second-generation cryptocurrencies</p>

<p>提到密码货币当然不可不提比特币Bitcoin，可以说是历史上最成功的密码货币，但是其大起大落确实富了不少人，也估计让不少人破产。比特币的经济价值就不多说了，在学术界很多论文开始研究比特币的安全性，发现攻击并提出替代方案。对比特币的兴趣形成了很多开源社区，而且很多修改或者扩展版本也被提出来。本文第一个提出对第二代密码现金的系统阐述，包含比特币以及很多变种。通过本文，可以对密码现金的系统属性有更加深刻的认知。</p>

<p>（3）The Miner&rsquo;s Dilemma</p>

<p>比特币火起来时，很多人开始去炒币，但据说真正赚钱的还是最早一批的挖矿者。挖矿形成了很多矿池（Pool），每个成员贡献其计算能力并分享奖励。而且很多大型的矿池都是开放性的，也就是任何人都可以参与进去分一杯羹。不过已经被证明矿池也是存在攻击的，一个成员可以无缝加入矿池中，但却不贡献其力量，这样矿池的收益被攻击者恭喜，每个真正参与计算的会有所损失。本文通过定义和分析游戏，对矿池的攻击进行了分析。</p>

<p>（4）Bitcoin over Tor isn&rsquo;t a good idea</p>

<p>这篇文章主要考虑比特币的匿名性。为了达到匿名性，有研究者提出可以通过Tor来连接比特币网络。Tor（<a href="https://www.torproject.org/%EF%BC%89%E6%98%AF%E7%AC%AC%E4%BA%8C%E4%BB%A3%E6%B4%8B%E8%91%B1%E8%B7%AF%E7%94%B1%EF%BC%88onion">https://www.torproject.org/%EF%BC%89%E6%98%AF%E7%AC%AC%E4%BA%8C%E4%BB%A3%E6%B4%8B%E8%91%B1%E8%B7%AF%E7%94%B1%EF%BC%88onion</a> routing）的一种实现，用户通过Tor可以在因特网上进行匿名交流。这篇文章证明组合Tor和比特币并不是一个好主意，容易导致新的攻击。</p>

<p>（5）Ad Injection at Scale: Assessing Deceptive Advertisement Modifications</p>

<p>这篇文章主要关注Web Injection。</p>

<h3>Session 3: Protocols and Network Security</h3>

<p>这个session主要是关注网络安全，研究网络中的一些安全协议的安全性，找到攻击并提出改进建议。不管怎样，网络安全也是很传统也永远不会过时的一个安全领域。不过，网络安全研究的范围很广，远不是下面五篇文章能涉及全面的。</p>

<p>（1）Connection-Oriented DNS to Improve Privacy and Security</p>

<p>DNS看起来对非链接的UDP协议来说很完美，实际上这个选择会导致很多问题：窃听，破坏隐私；源地址欺骗，使得DoS攻击更容易；注入攻击等。这篇文章提出DNS-X来解决这些问题。</p>

<p>（2）SoK: Secure Messaging</p>

<p>斯诺登事件发生后，关于国家对个人通信信息的窃听已经引起大家的重视，很多解决方案也声称能够提供安全和隐私信息。这包含很多新项目的出现，而且很多广泛使用的工具也增加了安全特征。过去两年巨大的压力要求快速交付安全解决方案，这导致了各种不同的威胁模型，不完整的目标，可疑的安全要求，对安全通行方面存在的密码相关文献缺乏广泛的视角。这篇文章，作者系统化总结并评估了当前的安全消息解决方案，并提出了一个评估框架来分析它们的安全性、可用性、容易接受等属性。本文既考虑学术界的解决方案，也考虑其它非学术文献但创新且有意思的方法。主要考虑了三个关键的挑战：可信建立（trust establishment）、安全会话（conversation security）和传输隐私（transport privacy）。可信建立方法提供强大的安全和隐私保护功能，但是在可用性和接受方面却表现很糟糕；不过，一些没有在学术界得到仔细研究的混合方法有可能在实际中提供更好的平衡。相比起来，一旦可信建立起来，大部分两方会话安全也能得到保证，不过多方会话还需要更加实际的解决方案。最后，传输隐私在不损失太多性能的情况下看起来是最难实现的问题。</p>

<p>（3）Temporal Lensing and its Application in Pulsing Denial-of-Service Attacks</p>

<p>Temporal Lensing 这个技术也是第一次听说，先科普一下。&#8221;temporal lensing&#8221;: a technique that concentrates a relatively low-bandwidth flood into a short, high-bandwidth pulse. 怎么用到DoS攻击里面就不是很了解了。</p>

<p>（4）How Secure and Quick is QUIC? Provable Security and Performance Analyses</p>

<p>QUIC（Quick UDP Internet Connections）是Google 2013年开发的一个安全传输协议，能减少网络延迟同时提供类似TLS的安全属性。本文主要是对该协议进行分析，包含可证明安全和性能评估。分析发现了QUIC协议存在的一些安全问题。</p>

<p>（5）Secure Track Verification</p>

<p>The paper proposes a new approach for securely verifying sequences of location claims from mobile nodes. 安全位置验证机制。</p>

<h3>Session 4: Cryptographic Protocols</h3>

<p>第四个session介绍密码协议方面的最新成果了，密码协议表面简单，可以里面的密码机制却很难，因此一般研究这块的主要以偏理论为主了。对于搞工程的，可以了解一下这些密码机制的作用还是很重要的，说不定哪天真能用上。</p>

<p>（1）Riposte: An Anonymous Messaging System Handling Millions of Users</p>

<p>这篇文章介绍了一个新的匿名广播消息系统，称为Riposte，并进行了原型实现，理论中比较偏工程的了。该系统可以防止流量分析攻击（traffic-analysis attacks），防止恶意客户端的匿名拒绝服务攻击，而且规模能达到百万级用户的匿名集合。使用了PIR（Private Information Retrieval）和安全多方计算MPC中的相关技术。</p>

<p>（2）Geppetto: Versatile Verifiable Computation</p>

<p>云计算引发了对可验证计算（Verifiable Computation）协议的兴趣，通过VC，一个弱客户端可以安全地外包计算给远程方。最近理论和实际上的改进已经大大降低了客户端验证计算结果正确性的开销，不过提供证明的开销还是不实际。这篇文章提出了一系列的补充技术来减少证明者的负担，同时增加证明者的灵活性。</p>

<p>（3）ADSNARK: Nearly Practical and Privacy-Preserving Proofs on Authenticated Data</p>

<p>认证数据的隐私证明，方法很理论，不过应用场景却比较实际（如可穿戴计算wearable computing, 智能计量smart metering, or 通用的B2B交互general business-to-business interactions）。凡是与隐私相关的研究都需要一定的密码积累吧。</p>

<p>（4）Secure Sampling of Public Parameters for Succinct Zero Knowledge Proofs</p>

<p>非交互式零知识证明（NIZKs）是一个非常有用的密码学工具，具有很多有前景的应用。不过，简单的NIZKs机制需要一个可信方来生成和发布公共参数，这些参数供所有证明者和验证者使用。这就出现一个问题，该可信方在实际可能并不可信或者根本不存在。本文主要关注这个问题，提出如何安全发布公共参数的解决方案。</p>

<p>（5）Forward Secure Asynchronous Messaging from Puncturable Encryption</p>

<p>本文提出一个新的机制，能实现forward secure encryption和forward messaging systems（如email和SMS）。</p>

<p>In a forward secure encryption scheme, a user periodically updates her secret key so that past messages remain confidential in the event that her key is compromised. A primary contribution of our work is to introduce a new form of encryption that we name puncturable encryption（提出了一种新的加密形式）. Using a puncturable encryption scheme, recipients may repeatedly update their decryption keys to revoke decryption capability for selected messages, recipients or time periods. Most importantly, this update process does not require the recipients to communicate with or distribute new key material to senders. We show how to combine puncturable encryption with the forward-secure public key encryption proposal of Canetti et al. to achieve practical forward-secure messaging with low overhead. We implement our schemes and provide experimental evidence that this new construction is practical.</p>

<h3>Session 5: ORAM and Secure Multi-Party Computation</h3>

<p>安全多方计算的研究可以说已经有了快30年的历史了，可谓经久不衰，可见其重要性。不过研究安全多方计算需要很好的理论基础，虽然很多方案提出来，但至今并没有很实用的方案。最近几年的方向好像是开始更多的关注实用方案。ORAM称为“Oblivious RAM”，该机制在让客户端访问远程存储时可以隐藏其访问模式，特别在云存储兴起后，研究ORAM的人也日益趋多。不管怎样，进入这个方向是需要理论基础的，比较难，不过每年在各种安全顶会上，这个方向的论文总是不少。先看看下面五篇论文。</p>

<p>（1）Privacy and Access Control for Outsourced Personal Records</p>

<p>云存储已经成为很多IT架构的基石，为备份、同步和大数据共享提供一个无缝的解决方案。不过，直接将用户数据交给云服务商控制，总会出现不少安全和隐私问题，如外包数据的完整性如何保证、敏感信息是否会意外或者故意泄露、用户活动是否被分析等等。而且，即便相信云服务商是可信，访问外包文档的用户也可能存在恶意行为。对于个人健康记录和信用评分等敏感应用，这些安全问题尤为严重。为了解决这个问题，这篇文章提出了一个密码系统，称为GORAM，即便云服务不可信且存在恶意客户端，该系统能保证外包数据的机密性和完整性，保证对访问这些数据的匿名性和不可链接性，而且允许数据拥有者将外包数据与其他客户端进行共享，选择性的给予他们读或者写的权限。GORAM声称是第一个在外包存储领域能达到如此广范围安全和隐私属性的密码系统。在构造该系统过程中，开发了两个新且通用的密码机制，分别为batched zero-knowledge proofs of shuffle 和 an accountability technique based on chameleon signatures。最后，为了评估有效性，作者在Amazon EC2云上对GORAM进行了实现。</p>

<p>（2）TinyGarble: Highly Compressed and Scalable Sequential Garbled Circuits</p>

<p>安全多方计算最早由华人Yao提出，当时他提出的解决方案为混淆电路，即Garbled Circuit（GC），这个方法堪称最有效的方案，一直研究至今。这篇论文的TinyGarble也是在Yao GC上的改进，提出了一个新的自动化方法来产生压缩布尔电路。</p>

<p>（3）GraphSC: Parallel Secure Computation Made Easy</p>

<p>使用机器学习的优势，同时提供用户数据隐私性，需要对一组广泛的数据挖掘算法的安全计算模型。这篇文章将安全计算引入到对大规模并行体系进行数据挖掘的编程框架中。总之，机器学习、数据挖掘、安全计算在这里结合了，能达到这样的效果：开发了一个编程范式使得非密码专家也可以编写安全代码；将并行带入这些算法的安全版本；满足茫然（obliviousness）的需求，即不泄露任何隐私信息。并以如何隐藏图结构为例子进行了分析。感觉消化这篇不容易，不过如何结合确实有点意思。</p>

<p>（4）Malicious-Client Security in Blind Seer</p>

<p>Blind Seer系统是SP 2014上提出一个有效可扩展的DBMS，能同时提供客户查询隐私和服务器数据保护。这篇文章对其进行改进，解决面对恶意客户端是如何解决的问题。使用了一个新的技术，称为SPF-SFE（a semi-private function secure function evaluation），SFE其实本质上就是安全多方计算，而半隐私函数SPF也是在这里第一次听说了。</p>

<p>（5）ObliVM: A Programming Framework for Secure Computation</p>

<p>只看介绍感觉这篇文章很牛，设计和开发了新一代自动安全计算框架，能够修补通用性和自定义之间的间隙，而且代码将对安全社区开源。看起来很有吸引力，到时一睹真容后再来分析分析。</p>

<h3>Session 6: Security du Jour</h3>

<p>“du jour”通常在餐馆形容今日特色菜，是今日特色、当今流行的意思，这个session的paper可能并不能划归为具体哪个方向，就全放在一起，形成今日特色安全吗？先看看这些特色在研究啥吧，有兴趣的也可以跟踪：</p>

<p>（1）SurroundWeb: Mitigating Privacy Concerns in a 3D Web Browser</p>

<p>将数字世界与真实世界的物体混合起来达到身临其境的体验正在成为现实。通过体感游戏Kinect，这些体验已经在智能手机和游戏设备中出现（如微软的XBOX游戏机），相信最终也会出现在设备无关的Web平台上。尽管炫酷，这些体验也带来了严峻的隐私问题，因为它们需要实时传感器输入来适当的混合数字和真实世界物体。之前的研究方法通过过滤、访问控制以及沙盒等来控制应用程序对传感器输入的访问，无法直接解决这种体验内部的显示任务。而且，这些低级解决方案无法整合到Web平台的高级GUI工具集中。这篇文章描述了如何扩展已有的Web平台，使得通过最小特权达到身临其境的呈现，并且在一个3D Web浏览器（微软研究院正在开发的SurroundWeb 3D浏览器）中实现了这些扩展。</p>

<p>（2）&#8221;I know what you did last summer&#8221; – Towards Making Systems Forget with Machine Unlearning</p>

<p>初看题目以为这篇会讲时下最热门的机器学习，仔细看发现是“Machine Unlearning”。不禁想起倚天屠龙中张三丰教张无忌太极拳的那一段，最高境界不是记住了多少招式，也是忘记了所有招式，随意出招。这里的“机器反学习”难道是要达到这个效果吗？这里的机器反学习就是要达到遗忘的效果，来保护用户的隐私，出发点很有意思，有空可以看看全文。In this paper, we focus on making learning systems forget, the process of which is defined as machine unlearning or unlearning. To perform unlearning upon learning system, we present general unlearning criteria, i.e., converting a learning system or part of it into a summation form of statistical query learning model, and updating all the summations to achieve unlearning.</p>

<p>（3）GenoGuard: Protecting Genomic Data Against Brute-Force Attacks</p>

<p>这篇似乎是安全与生物的一个结合，关注基因组数据的安全存储。提供了一个工具（称为GenoGuard）来对基因组数据进行当下和长期的强保护。</p>

<p>（4）SoK: A comprehensive analysis of game-based ballot privacy definitions</p>

<p>又是一篇关注隐私的文章，不过比较理论。作者以批判性思维（研究者需要具备的基本要素，但有时却很难达到）重新审视了投票方案中关于隐私的基于游戏的安全定义，除了发现之前的一些问题外，还揭露了一些没有注意到的缺陷。分析后，作者的总结是现有的定义没有一个满足要求，因此提出了一个新的基于游戏的隐私定义（a new game-based definition of privacy），称为BPRIV。</p>

<p>（5）Cracking-Resistant Password Vaults using Natural Language Encoders</p>

<p>“Password vaults”可以叫做“密码保险库”，用户记忆多个不同的密码是很困难的一件事，密码保险库通过将多个密码加密存储起来，用户只需要记住一个主密码即可。我之前的博文介绍的KeePass工具可以说也是这样的一个密码保险库。这样对用户非常方便，但是却很自然导致一个问题，即单点故障。攻击者获得用户的密码保险库后可能进行离线穷举攻击（offline brute-force attacks），一旦成功，那用户所有的密码都泄露了。这篇论文研究如何构建加密的保险库来抵制这种攻击，强制攻击者必须进行在线攻击。本文还介绍了一个新的安全编码机制，称为自然语言编码器natural-language encoders (NLEs)。</p>

<h3>Session 7: Protocols</h3>

<p>之前的Session有关注网络协议的，也有关注密码协议的，这个Session就叫协议，应该是各种协议都有吧，且看看先。</p>

<p>（1）Security of the J-PAKE Password-Authenticated Key Exchange Protocol</p>

<p>这篇文章分析J-PAKE协议的安全性，J-PAKE全称password-authenticated key exchange protocol（密码认证密钥交换协议），这个协议来自开源的OpenSSL密码库，已经在实际中得到了很多应用。</p>

<p>（2）Post-quantum key exchange for the TLS protocol from the ring learning with errors problem</p>

<p>结合格密钥交换和传统的基于RSA或者ECC的认证，研究公钥的人应该比较关心这个问题。</p>

<p>（3）A Messy State of the Union: Taming the Composite State Machines of TLS</p>

<p>这篇分析传输层安全协议TLS，分析的是其开源实现版本中的问题，发现攻击并提出解决方法。</p>

<p>（4）Vetting SSL Usage in Applications with SSLINT</p>

<p>这是第二篇国内研究机构的论文，来自浙江大学的Boyuan He。论文也是分析传输层安全协议SSL和TLS的，不过分析的不是协议本身，而是分析对其API的使用。对SSL/TLS APIs的不正确使用可能造成攻击，很多可能是由于API本身设计的问题，或者是应用开发者经验不足导致的，造成数据泄露或者中间人攻击。为了保证应用程序使用SSL/TLS时的代码质量和逻辑正确性，该论文提出了一个可扩展的自动检测系统SSLINT，可以检测对SSL/TLS APIs的不正确使用。该系统基于静态分析技术，通过分析Ubuntu系统中的应用，找到了27个未知的SSL/TLS漏洞。</p>

<h3>Session 8: Side Channels</h3>

<p>侧信道（或者边信道）攻击也是很经典的密码问题，研究也几十年的历史了。这种攻击并不是密码分析或者暴力破解，而是分析密码系统的物理实现中获得的信息，如时间信息、功耗、电磁泄露或者甚至声音都可能提供一个额外的信息源，从而被利用来攻击密码系统。由于笔者并不研究这一块，主要简介一下，以科普为主。</p>

<p>（1）Controlled-Channel Attacks: Deterministic Side Channels for Untrusted Operating Systems</p>

<p>这篇介绍控制信道攻击Controlled Channel attacks，一种新类型的侧信道攻击，该攻击中一个不可信的操作系统可以从Overshadow、lnkTag或者Haven保护的应用程序中提取大量的敏感信息。</p>

<p>（2）S$A: A Shared Cache Attack that Works Across Cores and Defies VM Sandboxing—and its Application to AES</p>

<p>这是关于虚拟平台上的一个侧信道攻击。In this work, we introduce a fine-grain cross-core cache attack that exploits access time variations on the last level cache. The attack exploits huge pages to work across VM boundaries without requiring deduplication.</p>

<p>（3）Last-Level Cache Side-Channel Attacks are Practical</p>

<p>We present an effective implementation of the Prime+Probe side-channel attack against the last-level cache. We measure the capacity of the covert channel the attack creates and demonstrate a cross-core, cross-VM attack on multiple versions of GnuPG. Our technique achieves a high attack resolution without relying on weaknesses in the OS or hypervisor or on sharing memory between attacker and victim.</p>

<p>（4）On Subnormal Floating Point and Abnormal Timing</p>

<p>这篇关于时间信道攻击。We identify a timing channel in the floating point instructions of modern x86 processors: the running time of floating point addition and multiplication instructions can vary by two orders of magnitude depending on their operands. 现在大部分PC还是采用x86处理器，这个攻击如果能够实用也是非常危险的。</p>

<h3>Session 9: Malware and Program Analysis</h3>

<p>这个Session是恶意代码分析，比较实用，大家常关注的黑客或者极客主要是这块了。恶意代码分析过程绝对是个枯燥的过程。</p>

<p>（1）Cross-Architecture Bug Search in Binary Executables</p>

<p>With the general availability of closed-source software for various CPU architectures, there is a need to identify security-critical vulnerabilities at the binary level to perform a vulnerability assessment. Unfortunately, existing bug finding methods fall short in that they i) require source code, ii) only work on a single architecture (typically x86), or iii) rely on dynamic analysis, which is inherently difficult for embedded devices. In this paper, we propose a system to derive bug signatures for known bugs. We then use these signatures to find bugs in binaries that have been deployed on different CPU architectures (e.g., x86 vs. MIPS). The variety of CPU architectures imposes many challenges, such as the incomparability of instruction set architectures between the CPU models. We solve this by first translating the binary code to an intermediate representation, resulting in assignment formulas with input and output variables. We then sample concrete inputs to observe the I/O behavior of basic blocks, which grasps their semantics. Finally, we use the I/O behaviors to find code parts that behave similar to the bug signature, effectively revealing code parts that contain the bug. We have designed and implemented a tool for cross-architecture bug search in executables. Our prototype currently supports three instruction set architectures (x86, ARM, and MIPS) and can find vulnerabilities in buggy binary code for any of these architectures. We show that we can find Heartbleed vulnerabilities, regardless of the underlying software instruction set. Similarly, we apply our method to find backdoors in closed- source firmware images of MIPS- and ARM-based routers.</p>

<p>（2）The Attack of the Clones: A Study of the Impact of Shared Code on Vulnerability Patching</p>

<p>Vulnerability exploits remain an important mech- anism for malware delivery, despite efforts to speed up the creation of patches and improvements in software updating mech- anisms. Vulnerabilities in client applications are often exploited in spear phishing attacks and cannot be discovered using network vulnerability scanners. Analyzing their lifecycle is challenging because it requires observing the deployment of patches on hosts around the world. Using 5-year data collected on 8.4 million hosts, available through Symantec’s WINE platform, we present the first systematic study of patch deployment in client-side vulnerabilities. Our analysis of the vulnerability lifecycle of 10 popular client applications identifies several new threats presented by multiple installations of the same program and shared libraries that may be distributed with multiple applications. We find that 80 vulnerabilities in our data set affect common code shared by two applications. In these cases, the time between patch releases in the different applications is up to to 118 days (with a median of 11 days). Furthermore, as the patching rates differ between applications, many hosts patch the vulnerability in one application but not in the other one. We demonstrate two novel attacks that enable exploitation by invoking old versions of applications that are used infrequently, but that remain installed. We also find that the patch rate is affected by user-specific and application-specific factors; for example, hosts belonging to security analysts and applications with an automated updating mechanism have significantly lower median times to patch.</p>

<p>（3）SoK: Deep Packer Inspection: A Longitudinal Study of the Complexity of Run-Time Packers</p>

<p>Run-time packers are typically used by malware-writers to obfuscate their code and hinder static analysis. The packer problem has been widely studied, and several solutions have been proposed in order to generically unpacked these protected binaries. Nevertheless, these solutions commonly rely on certain assumptions that may not necessarily be met by certain types of packers. In this paper, we propose a taxonomy to measure runtime packer complexity, and evaluate it over two datasets composed of both off-the-shelf packers and custom packed binaries. Also, we propose a set of heuristics to improve the feasibility of multi-path exploration approaches for recovering the code of packers that unprotect their code on demand.</p>

<p>（4）A Generic Approach to Automatic Deobfuscation of Executable Code</p>

<p>Malicious software are usually obfuscated to avoid detection and resist analysis. When new malware is encountered, such obfuscations have to be penetrated or removed (&ldquo;deobfuscated&rdquo;) in order to understand the internal logic of the code and devise countermeasures. This paper discusses a generic approach for deobfuscation of obfuscated executable code. Our approach does not make any assumptions about the nature of the obfuscations used, but instead uses semantics-preserving program transformations to simplify away obfuscation code. We have applied a prototype implementation of our ideas to a variety of different kinds of obfuscation, including emulation-based obfuscation, emulation-based obfuscation with runtime code unpacking, and return-oriented programming. Our experimental results are encouraging and suggest that this approach can be effective in extracting the internal logic from code obfuscated using a variety of obfuscation techniques, including tools such as Themida that previous approaches could not handle.</p>

<p>（5）Program-Adaptive Mutational Fuzzing</p>

<p>In this work, we propose a novel way to maximize the number of bugs found for black-box mutational fuzzing given a program and a seed input. The major intuition is to leverage a white-box symbolic analysis on an execution trace for a given program-seed pair to optimize parameters for mutational fuzzing. The result is promising: we found 25% more bugs than the state- of-the-art fuzzers over 8 applications, given a limited resource. We make our code publicly available to foster open science.</p>

<h3>Session 10: Memory Integrity</h3>

<p>内存完整性，这个session的技术都比较难，需要多年的积累。内存完整性分析都与实际攻击相关，如内存泄露攻击、代码重用攻击、ROP攻击等等。用到的解决技术都需要对系统底层了解比较透彻。</p>

<p>（1）Micro-Policies: Formally Verified, Tag-Based Security Monitors</p>

<p>Recent advances in hardware design have demonstrated mechanisms allowing a wide range of low-level security policies micro-policies to be expressed using rules on metadata tags. We propose a methodology for defining and reasoning about such tag-based reference monitors in terms of a high-level &ldquo;symbolic machine,&rdquo; and we use this methodology to define and formally verify micro-policies for dynamic sealing, compartmentalization, control-flow integrity, and memory safety; in addition, we show how to use the tagging mechanism to protect its own integrity. For each micro-policy, we prove by refinement that the symbolic machine instantiated with the policy&rsquo;s rules embodies a high-level specification characterizing a useful security property. Last, we show how the symbolic machine itself can be implemented in terms of a hardware rule cache and a software controller.</p>

<p>（2）Counterfeit Object-oriented Programming: On the Difficulty of Preventing Code Reuse Attacks in C++ Applications</p>

<p>Code reuse attacks（代码重用攻击） such as return-oriented programming (ROP) are prevalent and powerful and are widely used to exploit memory corruption vulnerabilities in software programs. Recently, many defenses were proposed to mitigate code reuse attacks, but some of them have already been successfully broken. In this paper, we perform a systematic assessment of recently proposed CFI solutions and other defenses against code reuse attacks in the context of object-oriented languages. We focus on C++ since this programming language is used by a large number of today&rsquo;s most attacked software projects (e.g., web browsers, document viewers, and other programming languages&#8217; runtime interpreters). We demonstrate that almost all CFI solutions and many other defenses that do not consider object-oriented C++ semantics can be bypassed in practice. Our novel attack technique, denoted as COOP (counterfeit object-oriented programming), induces malicious program behavior by only invoking chains of a program&rsquo;s existing virtual functions through legitimate call sites. COOP is Turing complete under realistic conditions and we demonstrate its viability by developing complex, real-world exploit codes for Internet Explorer 10 on Windows and Firefox 36 on Linux. We also show that even recently proposed defenses (Code-Pointer Separation, T-VIP, vfGuard, and VTint) that specifically target C++ are vulnerable to COOP. Our observation is that no strong defense against COOP exists today that does not require access to source code, and constructing such a defense seems to be challenging. We believe that our investigation and results are helpful contributions to the design and implementation of future defense systems against the severe threat of control-flow hijacking attacks that has sustained in the wild for more than two decades.</p>

<p>（3）Automatic Inference of Search Patterns for Taint-Style Vulnerabilities</p>

<p>Taint-style vulnerabilities are a persistent problem in software development, as the recently discovered &ldquo;Heartbleed&rdquo; vulnerability strikingly illustrates. In this class of vulnerabilities, attacker-controlled data is passed unsanitized from an input source to a sensitive sink. While simple instances of this vulnerability class can be detected automatically, more subtle defects involving data flow across several functions or project- specific APIs are mainly discovered by manual auditing. Different techniques have been proposed to accelerate this process by searching for typical patterns of vulnerable code. However, all of these approaches require a security expert to manually model and specify appropriate patterns in practice. In this paper, we propose a method for automatically inferring search patterns for taint-style vulnerabilities in C code. Given a security-sensitive sink, such as a memory function, our method automatically identifies corresponding source-sink systems and constructs patterns that model the data flow and sanitization in these systems. The inferred patterns are expressed as traversals in a code property graph and enable efficiently searching for unsanitized data flows—across several functions as well as with project-specific APIs. We demonstrate the efficacy of this approach in different experiments with 5 open-source projects. The inferred search patterns reduce the amount of code to inspect for finding known vulnerabilities by a factor of 19.5 (94.9%) and also enable us to uncover 8 previously unknown vulnerabilities.</p>

<p>（4）Readactor: Practical Code Randomization Resilient to Memory Disclosure</p>

<p>Code-reuse attacks such as return-oriented programming (ROP) pose a severe threat to modern software. Designing practical and effective defenses against code-reuse attacks is highly challenging. One line of defense builds upon fine-grained code diversification to prevent the adversary from constructing a reliable code-reuse attack. However, all solutions proposed so far are either vulnerable to memory disclosure or are impractical for deployment on commodity systems. In this paper, we address the deficiencies of existing solutions and present the first practical, fine-grained code randomization defense, called Readactor, resilient to both static and dynamic ROP attacks. We distinguish between direct memory disclosure, where the attacker reads code pages, and indirect memory disclosure, where attackers use code pointers on data pages to infer the code layout without reading code pages. Unlike previous work, Readactor resists both types of memory disclosure. Moreover, our technique protects both statically and dynamically generated code. We use a new compiler-based code generation paradigm that uses hardware features provided by modern CPUs to enable execute-only memory and hide code pointers from leakage to the adversary. Finally, our extensive evaluation shows that our approach is practical&mdash;we protect the entire Google Chromium browser and its V8 JIT compiler&mdash;and efficient with an average SPEC CPU2006 performance overhead of only 6.4%.</p>

<p>（5）Missing the Point: On the Effectiveness of Code Pointer Integrity</p>

<p>Memory corruption attacks （内存泄露攻击）have been known for decades, but they are still a major vector of attack for compromising modern systems. Numerous defenses have been proposed against memory corruption attacks, but they all have their limitations and weaknesses. Stronger defenses such as complete memory safety incur a large overhead, while weaker ones such as practical control flow integrity have been shown to be ineffective. A recent technique called code pointer integrity (CPI) promises to provide the best of both security and performance worlds, preventing control hijacking attacks while maintaining low overhead. In this paper, we show that the assumptions made by CPI are fundamentally flawed and in fact CPI can be bypassed using existing, known types of vulnerabilities. We show that CPI’s safe region can be leaked and then maliciously modified by using data pointer overwrites. Although many other implementation bugs exist in CPI, for this work we assume the weakest assumptions for the attacker and the strongest implementation of CPI and show that just by controlling the stack, an attacker can easily bypass CPI. Our attack was implemented as a proof-of-concept against Nginx and could successfully bypass CPI in 6 seconds with 13 observed crashes. We also present an attack that generates no crashes and is able to bypass CPI in 98 hours.</p>

<h3>Session 11: Security du Jour II</h3>

<p>这是第二个特色安全Session了，通过对之前特色论文的了解，论文应该都具有一定的新颖性和吸引力。</p>

<p>（1）Securing Multiparty Online Services via Certified Symbolic Transactions</p>

<p>现在很多在线服务（如单点登录、第三方支付等）都存在安全缺陷，对程序进行形式化验证变得很需要。不过程序验证在现实世界中存在很多障碍：协议规范通常很模糊，如果描述其安全属性；如何对攻击者和运行时平台建模；如何处理交易中的无限集合（the unbounded set）。这篇文章介绍认证符合交易Certified Symbolic Transaction (CST)，可以大大降低程序验证方法使用的障碍。</p>

<p>（2）Caelus: Verifying the Consistency of Cloud Services with Battery-Powered Devices</p>

<p>云存储服务，如Amazon S3、DropBox、Google Drive、Microsoft OneDrive、百度云等已经日益流行。不过，用户不可能完全相信云服务。目前提出的对云存储的解决方案，当用到电池供电的设备中都存在不足，如或者需要设备长期开启以便通信，或者需要依赖一个可信服务来传递消息，或者无法提供及时的攻击检测。这篇论文提出Caelus，可以解决这些不足。The key insight that enables Caelus to do this is having the cloud service declare the timing and order of operations on the cloud service. Our experiments show that Caelus can detect consistency violations on Amazon’s S3 service when the desired consistency requirements set by the user are stricter than what S3 provides. Caelus achieves this with a roughly 12.6% increase in CPU utilization on clients, 1.3% of network bandwidth overhead and negligible impact on the battery life of devices.</p>

<p>（3）High System-Code Security with Low Overhead</p>

<p>由于编写安全系统代码是非常困难的，导致安全漏洞长期困扰着现代各种系统。好的方法通过运行时检测实现期望的安全策略能够自动改造安全，不过诱发的系统变慢导致很多用户难以接受，使得这些工具很少被使用。这样，现实系统的不安全性就一直存在。这篇文章就帮助开发者如何优雅的处理性能问题，在安全性和性能上达到一种平衡。We present an approach in which developers/operators can specify what level of overhead they find acceptable for a given workload (e.g., 5%); our proposed tool ASAP then automatically instruments the program to maximize its security while staying within the specified &ldquo;overhead budget.&rdquo; Two insights make this approach effective: most overhead in existing tools is due to only a few &ldquo;hot&rdquo; checks, whereas the checks most useful to security are typically &ldquo;cold&rdquo; and cheap. We evaluate ASAP on programs from the Phoronix and SPEC benchmark suites. It can precisely select the best points in the security-performance spectrum. Moreover, we analyzed existing bugs and security vulnerabilities in RIPE, OpenSSL, and the Python interpreter, and found that the protection level offered by the ASAP approach is sufficient to protect against all of them.</p>

<p>（4）Understanding and Monitoring Embedded Web Scripts</p>

<p>Web浏览器经常使用各种第三方脚本，安全隐患自然而来。这篇文章介绍他们开发的一些工具，可以帮助站点管理员来理解、监控和限制嵌入到他们站点的第三方脚本的行为。关注Web安全的研究者可以学习使用下这篇文章的工具，看看是否能有很好的效果。</p>

<h3>Session 12: Android Security</h3>

<p>移动互联网应该是时下最热门的，移动安全自然也不例外，不过SP上居然最后一个session才讨论这一块，而且局限于安卓安全。一方面可以看到Android系统在移动市场中的地位，另一方面可以发现在移动安全这块的研究才刚刚起步。这里的论文都是关于移动Apps可能访问移动设备上的用户敏感信息的。</p>

<p>（1）Effective Real-time Android Application Auditing</p>

<p>这篇文章也有来自国内研究机构的作者，来自上海交大的Lu Gong（二作）。</p>

<p>移动Apps可以访问移动设备上的各种私人数据，如通讯录、短信等。这容易造成数据泄露，App审计是一个基本的程序分析任务，可以发现数据泄露的代码路径。目前，静态分析技术用的比较多，因为其可以精确找到整个程序中有问题的数据流。不过，静态分析也容易产生错误报警，需要手动确认；而且存在的静态分析方法可能需要数分钟或者甚至几个小时才能检查完一个App，这是很不实际的。为了克服这些限制，本文设计了AppAudit，结合静态分析和动态分析技术。They design AppAudit to use an efficient but over-estimating static API analysis first and then relies on a dynamic analysis to prune its false positives. Overall, AppAudit achieves a low false positive rate as the dynamic analysis only explores possible code paths during real execution. AppAudit also achieves short analysis time by combining an efficient static stage with a highly parallelizable dynamic stage.</p>

<p>（2）What the App is That? Deception and Countermeasures in the Android User Interface</p>

<p>用户只能通过视觉外观来识别一个App是存在安全风险的。这篇文章进行更加本质的分析和识别，帮助用户以免误信其它App。In this paper, we analyze in detail the many ways in which Android users can be confused into misidentifying an app, thus, for instance, being deceived into giving sensitive information to a malicious app. Our analysis of the Android platform APIs, assisted by an automated state-exploration tool, led us to identify and categorize a variety of attack vectors (some previously known, others novel, such as a non-escapable fullscreen overlay) that allow a malicious app to surreptitiously replace or mimic the GUI of other apps and mount phishing and click-jacking attacks.</p>

<p>（3）Leave Me Alone: App-level Protection Against Runtime Information Gathering on Android</p>

<p>Stealing of sensitive information from apps is always considered to be one of the most critical threats to Android security. Recent studies show that this can happen even to the apps without explicit implementation flaws, through exploiting some design weaknesses of the operating system, e.g., shared communication channels such as audio and Bluetooth, and side channels like CPU, memory, network-data usages, etc. In all these attacks, a malicious app needs to run side-by-side with the target app (the victim) to collect its runtime information. Examples include recording phone conversations from the phone app, gathering network-data usages of WebMD to infer the disease condition the user looks at, etc（攻击例子）. This runtime-information-gathering (RIG) threat is both realistic and serious, as demonstrated by prior research and our new findings, which reveal that the adversary monitoring daily operations of popular Android-based home security systems can easily figure out when the house is empty and the user is not looking at surveillance cameras, and even turn off the alarm delivered to the user&rsquo;s phone. To defend against this new category of attacks, we propose a novel technique that changes neither the operating system nor the target apps, and provides immediate protection as soon as an ordinary app (with only normal and dangerous permissions) is installed（本文提出的防止攻击的新技术）. This new approach, called App Guardian（称为App守卫）, thwarts a malicious app&rsquo;s runtime monitoring attempt by pausing all suspicious background processes when the target app (called principal) is running in the foreground, and resuming them after the app stops and its runtime environment is cleaned up. Our technique leverages a unique feature of Android, on which third-party apps running in the background are often considered to be disposable and can be stopped anytime with only a minor performance and utility implication. We further limit such an impact by only focusing on a small set of suspicious background apps, which are identified based upon their behaviors inferred from their side channels, such as thread names, CPU scheduling data and kernel time. App Guardian is also carefully designed to choose the right moments to start and end the protection procedure, and effectively protect itself against malicious apps. Our experimental studies show that this new technique defeated all known RIG attacks, ranging from phone taping to keylogging through various side channels. In the meantime, the inconvenience it introduces is found to be minimal, with negligible impacts on the utility of legitimate apps and the performance of the OS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[优秀资料推荐]]></title>
    <link href="http://secdr.github.io/2015/05/03/good-papers/"/>
    <updated>2015-05-03T23:25:28-07:00</updated>
    <id>http://secdr.github.io/2015/05/03/good-papers</id>
    <content type="html"><![CDATA[<p>本页面会定期推荐个人认为一些不错的安全资料：</p>

<h4>1. 优秀论文推荐</h4>

<p><a href="https://github.com/secdr/sec-paper">awesome security paper </a>: 主要用于收集一些最新的安全论文，其论文PDF可以直接下载后阅读，如果阅读完后有写读后笔记，请麻烦留言并附上地址。</p>

<h4>2. 论文写作与资料分享</h4>

<p><a href="https://github.com/secdr/research-method">research-method</a>: 主要用于分享论文写作思路，写作方法和投稿事项等，基本上囊括了论文写作过程中的各种问题。</p>

<p>论文的写作一般会经历如下步骤：</p>

<ul>
<li>how to think: 如何寻找适合自己的论文观点或者议题；</li>
<li>how to search: 有了议题了如何去查找已有的研究成果和相关工作；</li>
<li>how to write: 如何去写一篇论文；</li>
<li>how to submit: 论文写好了如何去投稿；</li>
<li>how to revise: 收到修改意见后如何去回复和修改论文；</li>
<li>how to use template: 写作中会遇到各种文档的套词。</li>
</ul>


<h4>3. 科研方面的公开数据</h4>

<p><a href="https://github.com/secdr/research-database">research-database</a>: 数据的好与坏可以说决定了你能做成什么论文，针对目前科研数据获取难的问题，本项目旨在收集公开的数据。</p>

<h4>4. 安全科研工具</h4>

<p><a href="https://github.com/secdr/research-tool">research-tool</a>: 主要用于分享安全科研中的一些相关工具，对于入门的一些朋友可能帮助比较大。</p>

<h4>5. 安全期刊推荐</h4>

<p><a href="https://github.com/secdr/sec-journal">sec-journal</a>: 主要收集安全期刊，虽然安全期刊比较少，但是投稿时间，难易程度完全不同，此工程主要是方便大家在投稿的适合可以参考。</p>

<h4>6. LaTex写作模板</h4>

<p><a href="https://github.com/secdr/latex_template">latex_template</a>: 主要用于收集一些安全会议和杂志的LaTex文档模板，如果有新的模板也请推送。</p>
]]></content>
  </entry>
  
</feed>
